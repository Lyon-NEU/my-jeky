---
layout: post
title: "hbase定期备份"
description: ""
category: habase
tags: []
published: true
---
{% include JB/setup %}

## Hbase数据表定期备份

hbase备份网上有好几种方式，但由于这只有一个集群，所以采用hbase自带的命令进行备份：    
`hbase org.apache.hadoop.hbase.mapreduce.Export raw_data /home/nutch/hbase-backup/ 1483200000 1485100800
`  

上面有几个参数分别表示 数据表,存储路径，起始时间与结束时间，网上说如果存储在hdfs需要明确指定路径，但是实际过程中，上面这样写也是正确的。我们可以自己编写`python`脚本或`shell`脚本来执行该命令。  

```python
##转载一份使用Export与Import定期备份的Python代码。每月15日做一次完整备份，每天进行一次增量备份
import time    
import datetime    
from datetime import date    
import sys    
import os    
    
tablename=sys.argv[1]    
backupDst=sys.argv[2]    
today=date.today()    
if today.day == 15:    //every month, we do a full backup    
        backupSubFolder=backupDst+today.isoformat()+"-full"    
        cmd="hbase org.apache.hadoop.hbase.mapreduce.Export %s %s"%(tablename,backupSubFolder)    
else:    
    
        yesterday=datetime.date.today()- datetime.timedelta(days=1)    
        todayTimeStamp=time.mktime(today.timetuple())    
        yesTimeStamp=time.mktime(yesterday.timetuple())    
        backupSubFolder=backupDst+today.isoformat()    
        cmd="hbase org.apache.hadoop.hbase.mapreduce.Export %s %s %s"%(tablename,backupSubFolder,str(int(todayTimeStamp)*1000))    
    
print cmd    
    
os.system(cmd)  

##注意最后的cmd字符串构建，视HBase版本在对应位置添加上版本号
```
由于权限和环境变量问题，运行上面程序时，提示找不到hadoop命令，所以我就将该命令写入shell文件，然后编辑`crontab`，完成定期运行。整个的流程大概如下:

- 新建hbase-bak.sh：

```bash
[nutch@nutch-1 ~]$ cd /home/nutch/
[nutch@nutch-1 ~]$ vim hbase-bak.sh
#! /bin/bash
. /etc/profile
. ~/.bash_profile

saveData(){
        nohup hbase org.apache.hadoop.hbase.mapreduce.Export scores_test /home/nutch/`date +%Y%m%d` &
}
saveData
```

- 新建copytolocal.sh,将数据从hdfs拷贝到本地，然后删除hdfs里的数据，本来想将命令写到一个shell,但是它只执行了保存命令，没有运行拷贝命令，所以我分开写到两个文件中，可以正常运行：

```bash

#! /bin/bash
. /etc/profile
. ~/.bash_profile

saveData(){
        nohup hbase org.apache.hadoop.hbase.mapreduce.Export scores_test /home/nutch/`date +%Y%m%d%H%M` &
}
copyToLocal(){
   hadoop fs -copyToLocal /home/nutch/`date +%Y%m%d` /data/hbase-backup &&   hadoop fs -rmr /home/nutch/`date +%Y%m%d`
}
clean(){
        echo "disable 'scores_test'" | hbase shell
        echo "drop 'scores_test'" | hbase shell
        echo "create 'scores_test','grade','course'" | hbase shell
}
#saveData
copyToLocal
#clean

``` 

- 删除原hbase表中的数据，重新建立表。再用命令将数据导入hbase的时候，发现表必须是空的，如果直接导入原先的表，则不成功，新建一个空表后，则能正确导入。

- 编辑crontab命令
> 0 1 * * * /home/nutch/hbase-bak.sh  
> 10 1 * * * /home/nutch/copytToLocal.sh  

- 查看日志，确认命令是否正确运行: 
`tail -f /var/spool/mail/nutch`  
